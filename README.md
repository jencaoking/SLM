# é—®ç­”ç³»ç»Ÿæ¨¡å‹è®­ç»ƒè„šæœ¬

åŸºäºPyTorchå’ŒTransformeræ¶æ„çš„é—®ç­”ç³»ç»Ÿæ¨¡å‹è®­ç»ƒè„šæœ¬ï¼Œä¸“ä¸ºä¸­å›½å¤§é™†ç½‘ç»œç¯å¢ƒä¼˜åŒ–ï¼Œæ”¯æŒç¦»çº¿è®­ç»ƒå’Œå¤šç§æ•°æ®æ ¼å¼ã€‚

## ğŸŒŸ æ ¸å¿ƒç‰¹æ€§

- **å®Œæ•´çš„Transformeræ¶æ„**ï¼šè‡ªå®ç°çš„ç¼–ç å™¨-è§£ç å™¨æ¨¡å‹ï¼Œä¸“é—¨é’ˆå¯¹é—®ç­”ä»»åŠ¡ä¼˜åŒ–
- **å¤šæ ¼å¼æ•°æ®æ”¯æŒ**ï¼šæ”¯æŒCSVã€JSONã€JSONLã€TSVã€Parquetç­‰å¤šç§æ•°æ®æ ¼å¼
- **ä¸­å›½å¤§é™†ç½‘ç»œé€‚é…**ï¼šæ”¯æŒHuggingFaceé•œåƒæºã€ç¦»çº¿æ¨¡å¼ã€é­”æ­ModelScope
- **æ™ºèƒ½æ•°æ®å¤„ç†**ï¼šè‡ªåŠ¨æ ¼å¼æ£€æµ‹ã€å­—æ®µæ˜ å°„ã€æ•°æ®éªŒè¯å’Œæ¸…æ´—
- **çµæ´»çš„åˆ†è¯å™¨**ï¼šæ”¯æŒä¸­è‹±æ–‡æ··åˆåˆ†è¯ï¼ŒåŸºäºjiebaçš„ä¸­æ–‡å¤„ç†
- **å…¨é¢çš„è¯„ä¼°æŒ‡æ ‡**ï¼šEMã€F1ã€BLEUã€ROUGEç­‰å¤šç§è¯„ä¼°æŒ‡æ ‡
- **æ£€æŸ¥ç‚¹ç®¡ç†**ï¼šè‡ªåŠ¨ä¿å­˜ã€æœ€ä½³æ¨¡å‹é€‰æ‹©ã€æ–­ç‚¹ç»­è®­
- **æ¨ç†æ¥å£**ï¼šæ”¯æŒå•ä¸ªæ¨ç†ã€æ‰¹é‡æ¨ç†ã€äº¤äº’æ¨¡å¼

## ğŸ“ é¡¹ç›®ç»“æ„

```
LLM/
â”œâ”€â”€ configs/                    # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ config.yaml            # ä¸»é…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ data_configs/          # æ•°æ®é›†é…ç½®
â”‚       â”œâ”€â”€ custom_data.yaml   # è‡ªå®šä¹‰æ•°æ®é…ç½®
â”‚       â””â”€â”€ squad_data.yaml    # SQuADæ•°æ®é…ç½®
â”œâ”€â”€ models/                    # æ¨¡å‹æ¶æ„
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ transformer.py         # ä¸»æ¨¡å‹
â”‚   â”œâ”€â”€ encoder.py            # ç¼–ç å™¨
â”‚   â”œâ”€â”€ decoder.py            # è§£ç å™¨
â”‚   â””â”€â”€ attention.py          # æ³¨æ„åŠ›æœºåˆ¶
â”œâ”€â”€ utils/                     # å·¥å…·æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py        # æ•°æ®åŠ è½½å™¨
â”‚   â”œâ”€â”€ data_processor.py     # æ•°æ®å¤„ç†å™¨
â”‚   â”œâ”€â”€ tokenizer.py          # åˆ†è¯å™¨
â”‚   â”œâ”€â”€ format_detector.py    # æ ¼å¼æ£€æµ‹å™¨
â”‚   â””â”€â”€ metrics.py            # è¯„ä¼°æŒ‡æ ‡
â”œâ”€â”€ data/                      # æ•°æ®ç›®å½•
â”‚   â””â”€â”€ raw/                  # åŸå§‹æ•°æ®
â”‚       â””â”€â”€ custom/           # è‡ªå®šä¹‰æ•°æ®æ–‡ä»¶
â”‚           â”œâ”€â”€ 1.jsonl       # ç¤ºä¾‹æ•°æ®æ–‡ä»¶1
â”‚           â””â”€â”€ 2.jsonl       # ç¤ºä¾‹æ•°æ®æ–‡ä»¶2
â”œâ”€â”€ train.py                  # è®­ç»ƒè„šæœ¬
â”œâ”€â”€ inference.py              # æ¨ç†è„šæœ¬
â”œâ”€â”€ data_validator.py         # æ•°æ®éªŒè¯è„šæœ¬
â”œâ”€â”€ test_system.py            # ç³»ç»Ÿæµ‹è¯•è„šæœ¬
â”œâ”€â”€ requirements.txt          # ä¾èµ–åŒ…
â””â”€â”€ README.md                 # é¡¹ç›®è¯´æ˜
```

> **æ³¨æ„**: è¿è¡Œæ—¶ä¼šè‡ªåŠ¨åˆ›å»ºå¿…è¦çš„ç›®å½•ï¼ˆå¦‚ checkpoints/ã€logs/ã€outputs/ã€data/processed/ã€data/cache/ ç­‰ï¼‰

### é¡¹ç›®æ¸…ç†

ä¸ºäº†ä¿æŒé¡¹ç›®æ•´æ´ï¼Œå»ºè®®å®šæœŸæ¸…ç†ä»¥ä¸‹ç›®å½•ï¼š

```bash
# æ¸…ç†Pythonç¼“å­˜æ–‡ä»¶
find . -type d -name "__pycache__" -exec rm -rf {} +
# æˆ–åœ¨Windowsä¸Šï¼š
for /d /r . %d in (__pycache__) do @if exist "%d" rd /s /q "%d"

# æ¸…ç†ç©ºçš„è¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼‰
# è¿™äº›ç›®å½•åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šé‡æ–°åˆ›å»º
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# å…‹éš†é¡¹ç›®ï¼ˆå¦‚æœéœ€è¦ï¼‰
git clone <repository_url>
cd LLM

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# æˆ–è€…
.venv\Scripts\activate     # Windows

# å®‰è£…ä¾èµ–ï¼ˆä½¿ç”¨å›½å†…é•œåƒæºï¼‰
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple

# å®‰è£…PyTorchï¼ˆæ ¹æ®CUDAç‰ˆæœ¬ï¼‰
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### 2. å‡†å¤‡æ•°æ®

å°†ä½ çš„é—®ç­”æ•°æ®æ”¾åœ¨ `data/raw/custom/` ç›®å½•ä¸‹ï¼Œæ”¯æŒä»¥ä¸‹æ ¼å¼ï¼š

> **æ•°æ®ç›®å½•**: é¡¹ç›®ä¸­å·²åŒ…å«ç¤ºä¾‹æ•°æ®æ–‡ä»¶ `1.jsonl` å’Œ `2.jsonl`ï¼Œä½ å¯ä»¥å‚è€ƒå…¶æ ¼å¼æˆ–æ›¿æ¢ä¸ºè‡ªå·±çš„æ•°æ®ã€‚

#### CSVæ ¼å¼
```csv
question,context,answer,answer_start
"ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ","æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯...","äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯",5
```

#### JSONæ ¼å¼
```json
{
  "data": [
    {
      "question": "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
      "context": "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯...",
      "answer": "äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯",
      "answer_start": 5
    }
  ]
}
```

#### JSONLæ ¼å¼
```jsonl
{"question": "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ", "context": "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½...", "answer": "äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯", "answer_start": 5}
```

### 3. æŸ¥çœ‹ç¤ºä¾‹æ•°æ®

é¡¹ç›®ä¸­å·²åŒ…å«ä¸¤ä¸ªç¤ºä¾‹æ•°æ®æ–‡ä»¶ï¼š
- `data/raw/custom/1.jsonl`: å°è§„æ¨¡ç¤ºä¾‹æ•°æ® (21.9KB)
- `data/raw/custom/2.jsonl`: å¤§è§„æ¨¡ç¤ºä¾‹æ•°æ® (17MB)

ä½ å¯ä»¥æŸ¥çœ‹è¿™äº›æ–‡ä»¶ä¾†äº†è§£æ•°æ®æ ¼å¼ï¼Œæˆ–è€…ç›´æ¥ä½¿ç”¨å®ƒä»¬è¿›è¡Œæµ‹è¯•ã€‚

### 4. æ•°æ®éªŒè¯

åœ¨è®­ç»ƒä¹‹å‰ï¼ŒéªŒè¯æ•°æ®æ ¼å¼å’Œè´¨é‡ï¼š

```bash
python data_validator.py --file data/raw/custom/qa_data.csv --output validation_report.txt
```

### 5. è®­ç»ƒæ¨¡å‹

```bash
# ä½¿ç”¨é»˜è®¤é…ç½®è®­ç»ƒ
python train.py

# ä½¿ç”¨è‡ªå®šä¹‰é…ç½®
python train.py --config configs/custom_config.yaml --seed 42
```

### 6. æ¨¡å‹æ¨ç†

```bash
# äº¤äº’æ¨¡å¼
python inference.py --model_path <è®­ç»ƒå®Œæˆçš„æ¨¡å‹è·¯å¾„> --mode interactive

# å•ä¸ªé—®é¢˜æ¨ç†
python inference.py --model_path <è®­ç»ƒå®Œæˆçš„æ¨¡å‹è·¯å¾„> --mode single \
    --question "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ" \
    --context "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯..."

# æ‰¹é‡æ¨ç†
python inference.py --model_path <è®­ç»ƒå®Œæˆçš„æ¨¡å‹è·¯å¾„> --mode file \
    --input_file test_data.json --output_file results.json
```

## ğŸ“Š ç³»ç»Ÿæµ‹è¯•

è¿è¡Œç»¼åˆæµ‹è¯•éªŒè¯ç³»ç»ŸåŠŸèƒ½ï¼š

```bash
python test_system.py
```

æµ‹è¯•åŒ…æ‹¬ï¼š
- æ•°æ®æ ¼å¼æ£€æµ‹
- æ•°æ®åŠ è½½åŠŸèƒ½
- æ•°æ®éªŒè¯åŠŸèƒ½
- åˆ†è¯å™¨åŠŸèƒ½
- æ•°æ®å¤„ç†åŠŸèƒ½
- æ¨¡å‹åˆ›å»º
- è¯„ä¼°æŒ‡æ ‡
- é…ç½®åŠ è½½

## âš™ï¸ é…ç½®è¯´æ˜

ä¸»è¦é…ç½®æ–‡ä»¶ `configs/config.yaml` åŒ…å«ä»¥ä¸‹éƒ¨åˆ†ï¼š

### æ¨¡å‹é…ç½®
```yaml
model:
  vocab_size: 30000          # è¯æ±‡è¡¨å¤§å°
  d_model: 512              # æ¨¡å‹ç»´åº¦
  n_heads: 8                # æ³¨æ„åŠ›å¤´æ•°
  n_layers: 6               # ç¼–ç å™¨å±‚æ•°
  d_ff: 2048                # å‰é¦ˆç½‘ç»œç»´åº¦
  dropout: 0.1              # Dropoutç‡
```

### è®­ç»ƒé…ç½®
```yaml
training:
  batch_size: 16            # æ‰¹æ¬¡å¤§å°
  learning_rate: 5e-4       # å­¦ä¹ ç‡
  num_epochs: 10            # è®­ç»ƒè½®æ•°
  gradient_accumulation_steps: 4  # æ¢¯åº¦ç´¯ç§¯æ­¥æ•°
  warmup_steps: 1000        # é¢„çƒ­æ­¥æ•°
```

### æ•°æ®é…ç½®
```yaml
data:
  datasets:
    - name: "custom_dataset"
      path: "data/raw/custom/qa_data.csv"
      format: "csv"
      weight: 1.0
      enabled: true
  
  max_length: 512           # æœ€å¤§åºåˆ—é•¿åº¦
  train_split: 0.8          # è®­ç»ƒé›†æ¯”ä¾‹
  val_split: 0.1            # éªŒè¯é›†æ¯”ä¾‹
  test_split: 0.1           # æµ‹è¯•é›†æ¯”ä¾‹
```

### ç½‘ç»œç¯å¢ƒé…ç½®
```yaml
network:
  offline_mode: true        # ç¦»çº¿æ¨¡å¼
  use_mirror: true          # ä½¿ç”¨é•œåƒæº
  mirror_endpoint: "https://hf-mirror.com"
  use_proxy: false          # æ˜¯å¦ä½¿ç”¨ä»£ç†
  proxy_url: "http://127.0.0.1:7890"
```

## ğŸŒ ä¸­å›½å¤§é™†ç½‘ç»œç¯å¢ƒé€‚é…

### 1. HuggingFaceé•œåƒæº
```bash
export HF_ENDPOINT=https://hf-mirror.com
```

### 2. ç¦»çº¿æ¨¡å¼
```bash
export TRANSFORMERS_OFFLINE=1
export HF_DATASETS_OFFLINE=1
```

### 3. é­”æ­ModelScope
```python
from modelscope import MsDataset
dataset = MsDataset.load('squad', subset_name='plain_text')
```

### 4. ä»£ç†é…ç½®
```bash
export HTTP_PROXY=http://127.0.0.1:7890
export HTTPS_PROXY=http://127.0.0.1:7890
```

## ğŸ“ˆ æ¨¡å‹æ€§èƒ½

### æ¨¡å‹æ¶æ„
- **ç¼–ç å™¨**: 6å±‚Transformerç¼–ç å™¨ï¼Œæ”¯æŒé—®é¢˜å’Œä¸Šä¸‹æ–‡çš„ç‹¬ç«‹ç¼–ç 
- **è§£ç å™¨**: ä¸“é—¨çš„é—®ç­”è§£ç å™¨ï¼ŒåŒ…å«é—®é¢˜-ä¸Šä¸‹æ–‡äº¤äº’å’Œç­”æ¡ˆæŒ‡é’ˆç½‘ç»œ
- **æ³¨æ„åŠ›æœºåˆ¶**: å¤šå¤´è‡ªæ³¨æ„åŠ›å’Œäº¤å‰æ³¨æ„åŠ›
- **ä½ç½®ç¼–ç **: æ”¯æŒæœ€å¤§512é•¿åº¦çš„ä½ç½®ç¼–ç 

### è®­ç»ƒç­–ç•¥
- **ä¼˜åŒ–å™¨**: AdamW with weight decay
- **å­¦ä¹ ç‡è°ƒåº¦**: Cosine Annealing with warmup
- **æ¢¯åº¦ç´¯ç§¯**: æ”¯æŒå¤§batch sizeè®­ç»ƒ
- **æ··åˆç²¾åº¦**: FP16è®­ç»ƒå‡å°‘å†…å­˜å ç”¨
- **æ—©åœæœºåˆ¶**: é˜²æ­¢è¿‡æ‹Ÿåˆ

### è¯„ä¼°æŒ‡æ ‡
- **ç²¾ç¡®åŒ¹é… (EM)**: å®Œå…¨åŒ¹é…çš„ç­”æ¡ˆæ¯”ä¾‹
- **F1åˆ†æ•°**: åŸºäºtokené‡å çš„F1åˆ†æ•°
- **BLEUåˆ†æ•°**: ç”Ÿæˆè´¨é‡è¯„ä¼°
- **ROUGEåˆ†æ•°**: å¬å›ç‡å¯¼å‘è¯„ä¼°

## ğŸ”§ é«˜çº§ç”¨æ³•

### è‡ªå®šä¹‰æ•°æ®é›†

1. åˆ›å»ºæ•°æ®é…ç½®æ–‡ä»¶ï¼š
```yaml
# configs/data_configs/my_dataset.yaml
dataset_info:
  name: "my_qa_dataset"
  description: "æˆ‘çš„é—®ç­”æ•°æ®é›†"
  
field_mappings:
  question:
    primary: "question"
    alternatives: ["query", "q", "é—®é¢˜"]
  context:
    primary: "context"
    alternatives: ["passage", "text", "ä¸Šä¸‹æ–‡"]
  answer:
    primary: "answer"
    alternatives: ["response", "ç­”æ¡ˆ"]
```

2. åœ¨ä¸»é…ç½®ä¸­å¼•ç”¨ï¼š
```yaml
data:
  datasets:
    - name: "my_dataset"
      path: "data/raw/my_data.json"
      format: "json"
      config: "configs/data_configs/my_dataset.yaml"
```

### åˆ†å¸ƒå¼è®­ç»ƒ

```bash
# å¤šGPUè®­ç»ƒ
python -m torch.distributed.launch --nproc_per_node=2 train.py

# ä½¿ç”¨accelerateï¼ˆæ¨èï¼‰
accelerate config
accelerate launch train.py
```

### æ¨¡å‹å¾®è°ƒ

```bash
# ä»é¢„è®­ç»ƒæ¨¡å‹å¼€å§‹å¾®è°ƒ
python train.py --config configs/finetune_config.yaml \
    --pretrained_model <é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„>
```

### APIæœåŠ¡éƒ¨ç½²

```python
# app.py
from fastapi import FastAPI
from inference import QAInference

app = FastAPI()
# ä½¿ç”¨è®­ç»ƒå®Œæˆçš„æ¨¡å‹è·¯å¾„
qa_model = QAInference("<è®­ç»ƒå®Œæˆçš„æ¨¡å‹è·¯å¾„>")

@app.post("/predict")
async def predict(question: str, context: str):
    result = qa_model.predict_single(question, context)
    return result
```

## ğŸ› å¸¸è§é—®é¢˜

### Q: è®­ç»ƒæ—¶å†…å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ
A: å°è¯•ä»¥ä¸‹æ–¹æ³•ï¼š
- å‡å°batch_size
- å‡å°max_length
- å¯ç”¨gradient_accumulation_steps
- ä½¿ç”¨mixed_precisionè®­ç»ƒ

### Q: æ•°æ®åŠ è½½å¤±è´¥ï¼Ÿ
A: æ£€æŸ¥ï¼š
- æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®
- å­—æ®µåæ˜¯å¦åŒ¹é…
- æ–‡ä»¶ç¼–ç æ˜¯å¦ä¸ºUTF-8
- è¿è¡Œæ•°æ®éªŒè¯è„šæœ¬æ£€æŸ¥é—®é¢˜

### Q: æ¨¡å‹è®­ç»ƒä¸æ”¶æ•›ï¼Ÿ
A: å°è¯•ï¼š
- è°ƒæ•´å­¦ä¹ ç‡
- å¢åŠ warmup_steps
- æ£€æŸ¥æ•°æ®è´¨é‡
- è°ƒæ•´æ¨¡å‹å¤§å°

### Q: æ¨ç†ç»“æœä¸ç†æƒ³ï¼Ÿ
A: æ£€æŸ¥ï¼š
- è®­ç»ƒæ•°æ®è´¨é‡å’Œæ•°é‡
- æ¨¡å‹æ˜¯å¦æ”¶æ•›
- æ¨ç†æ—¶çš„confidence_threshold
- ç­”æ¡ˆé•¿åº¦é™åˆ¶

## ğŸ“ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨MITè®¸å¯è¯ï¼Œè¯¦è§LICENSEæ–‡ä»¶ã€‚

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestï¼

## ğŸ“§ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æäº¤Issueæˆ–è”ç³»ç»´æŠ¤è€…ã€‚

---

**æ³¨æ„**: æœ¬é¡¹ç›®ä¸“ä¸ºä¸­å›½å¤§é™†ç½‘ç»œç¯å¢ƒä¼˜åŒ–ï¼ŒåŒ…å«ç¦»çº¿æ¨¡å¼å’Œé•œåƒæºé…ç½®ï¼Œç¡®ä¿åœ¨ç½‘ç»œå—é™ç¯å¢ƒä¸‹ä¹Ÿèƒ½æ­£å¸¸ä½¿ç”¨ã€‚